{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total items: 500\n",
      "Items without error: 347\n",
      "Items with error: 153\n",
      "Filter file '../llm/data/mini_dev_filter.txt' has been created successfully.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Read the JSON file\n",
    "with open('../llm/data/mini_dev_refs.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Function to check if we should keep the row\n",
    "def should_keep(item):\n",
    "    return all('<error' not in tag and \"<warning\" not in tag for tag in item['sql_refs_annotated'])\n",
    "\n",
    "# Generate the filter list\n",
    "filter_list = ['TRUE' if should_keep(item) else 'FALSE' for item in data]\n",
    "\n",
    "# Write the filter list to a file\n",
    "with open('../llm/data/mini_dev_filter.txt', 'w') as f:\n",
    "    for item in filter_list:\n",
    "        f.write(f\"{item}\\n\")\n",
    "\n",
    "print(f\"Total items: {len(filter_list)}\")\n",
    "print(f\"Items without error: {filter_list.count('TRUE')}\")\n",
    "print(f\"Items with error: {filter_list.count('FALSE')}\")\n",
    "print(\"Filter file '../llm/data/mini_dev_filter.txt' has been created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "# pivot the data\n",
    "pivoted_data = defaultdict(lambda: defaultdict(list))\n",
    "for item in data:\n",
    "    if should_keep(item):\n",
    "        pivoted_data[item[\"db_id\"]][item[\"difficulty\"]].append(item)\n",
    "\n",
    "\n",
    "sample_counts = defaultdict(dict)\n",
    "sample_counts[\"california_schools\"][\"simple\"] = 2\n",
    "sample_counts[\"california_schools\"][\"moderate\"] = 3\n",
    "sample_counts[\"california_schools\"][\"challenging\"] = 1\n",
    "sample_counts[\"card_games\"][\"simple\"] = 3\n",
    "sample_counts[\"card_games\"][\"moderate\"] = 7\n",
    "sample_counts[\"card_games\"][\"challenging\"] = 1\n",
    "sample_counts[\"codebase_community\"][\"simple\"] = 4\n",
    "sample_counts[\"codebase_community\"][\"moderate\"] = 5\n",
    "sample_counts[\"codebase_community\"][\"challenging\"] = 1\n",
    "sample_counts[\"debit_card_specializing\"][\"simple\"] = 3\n",
    "sample_counts[\"debit_card_specializing\"][\"moderate\"] = 2\n",
    "sample_counts[\"debit_card_specializing\"][\"challenging\"] = 1\n",
    "sample_counts[\"european_football_2\"][\"simple\"] = 3\n",
    "sample_counts[\"european_football_2\"][\"moderate\"] = 5\n",
    "sample_counts[\"european_football_2\"][\"challenging\"] = 2\n",
    "sample_counts[\"financial\"][\"simple\"] = 1\n",
    "sample_counts[\"financial\"][\"moderate\"] = 4\n",
    "sample_counts[\"financial\"][\"challenging\"] = 2\n",
    "sample_counts[\"formula_1\"][\"simple\"] = 6\n",
    "sample_counts[\"formula_1\"][\"moderate\"] = 5\n",
    "sample_counts[\"formula_1\"][\"challenging\"] = 2\n",
    "sample_counts[\"student_club\"][\"simple\"] = 4\n",
    "sample_counts[\"student_club\"][\"moderate\"] = 4\n",
    "sample_counts[\"student_club\"][\"challenging\"] = 1\n",
    "sample_counts[\"superhero\"][\"simple\"] = 3\n",
    "sample_counts[\"superhero\"][\"moderate\"] = 5\n",
    "sample_counts[\"superhero\"][\"challenging\"] = 2\n",
    "sample_counts[\"thrombosis_prediction\"][\"simple\"] = 2\n",
    "sample_counts[\"thrombosis_prediction\"][\"moderate\"] = 5\n",
    "sample_counts[\"thrombosis_prediction\"][\"challenging\"] = 3\n",
    "sample_counts[\"toxicology\"][\"simple\"] = 1\n",
    "sample_counts[\"toxicology\"][\"moderate\"] = 3\n",
    "sample_counts[\"toxicology\"][\"challenging\"] = 4\n",
    "\n",
    "micro_dev_data = []\n",
    "\n",
    "for db_id, difficulties in sample_counts.items():\n",
    "    for difficulty, sample_count in difficulties.items():\n",
    "        # Seed of 8 is used because it's fairly close to the score of TA-gpt-4o with the full non-error non-warning set\n",
    "        sample_set = random.Random(8).sample(pivoted_data[db_id][difficulty], k=sample_count)\n",
    "        micro_dev_data.extend(sample_set)\n",
    "\n",
    "micro_dev_data = sorted(micro_dev_data, key=lambda x: x[\"question_id\"])\n",
    "micro_dev_question_ids = {item[\"question_id\"] for item in micro_dev_data}\n",
    "len(micro_dev_question_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total items: 500\n",
      "Items without error: 100\n",
      "Items with error: 400\n",
      "Filter file '../llm/data/mini_dev_filter.txt' has been created successfully.\n",
      "\n",
      "micro_dev_question_ids: [\n",
      "  36,\n",
      "  40,\n",
      "  41,\n",
      "  47,\n",
      "  48,\n",
      "  50,\n",
      "  98,\n",
      "  99,\n",
      "  115,\n",
      "  116,\n",
      "  128,\n",
      "  136,\n",
      "  159,\n",
      "  195,\n",
      "  218,\n",
      "  220,\n",
      "  226,\n",
      "  230,\n",
      "  236,\n",
      "  242,\n",
      "  263,\n",
      "  345,\n",
      "  346,\n",
      "  379,\n",
      "  397,\n",
      "  409,\n",
      "  412,\n",
      "  414,\n",
      "  415,\n",
      "  440,\n",
      "  465,\n",
      "  466,\n",
      "  537,\n",
      "  539,\n",
      "  555,\n",
      "  557,\n",
      "  565,\n",
      "  573,\n",
      "  578,\n",
      "  581,\n",
      "  586,\n",
      "  665,\n",
      "  732,\n",
      "  736,\n",
      "  739,\n",
      "  745,\n",
      "  750,\n",
      "  758,\n",
      "  761,\n",
      "  764,\n",
      "  769,\n",
      "  773,\n",
      "  850,\n",
      "  859,\n",
      "  868,\n",
      "  869,\n",
      "  872,\n",
      "  877,\n",
      "  892,\n",
      "  896,\n",
      "  902,\n",
      "  906,\n",
      "  909,\n",
      "  910,\n",
      "  954,\n",
      "  1037,\n",
      "  1048,\n",
      "  1057,\n",
      "  1076,\n",
      "  1079,\n",
      "  1080,\n",
      "  1088,\n",
      "  1092,\n",
      "  1102,\n",
      "  1103,\n",
      "  1155,\n",
      "  1157,\n",
      "  1164,\n",
      "  1179,\n",
      "  1189,\n",
      "  1192,\n",
      "  1195,\n",
      "  1201,\n",
      "  1281,\n",
      "  1302,\n",
      "  1340,\n",
      "  1346,\n",
      "  1357,\n",
      "  1359,\n",
      "  1376,\n",
      "  1378,\n",
      "  1380,\n",
      "  1381,\n",
      "  1399,\n",
      "  1473,\n",
      "  1476,\n",
      "  1480,\n",
      "  1493,\n",
      "  1507,\n",
      "  1515\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Generate the filter list\n",
    "question_ids_already_added = set()\n",
    "filter_list = []\n",
    "for item in data:\n",
    "    if item[\"question_id\"] in question_ids_already_added:\n",
    "        filter_list.append('FALSE')\n",
    "    elif item[\"question_id\"] in micro_dev_question_ids:\n",
    "        filter_list.append('TRUE')\n",
    "    else:\n",
    "        filter_list.append('FALSE')\n",
    "    question_ids_already_added.add(item[\"question_id\"])\n",
    "\n",
    "# Write the filter list to a file\n",
    "with open('../llm/data/mini_dev_filter.txt', 'w') as f:\n",
    "    for item in filter_list:\n",
    "        f.write(f\"{item}\\n\")\n",
    "\n",
    "print(f\"Total items: {len(filter_list)}\")\n",
    "print(f\"Items without error: {filter_list.count('TRUE')}\")\n",
    "print(f\"Items with error: {filter_list.count('FALSE')}\")\n",
    "print(\"Filter file '../llm/data/mini_dev_filter.txt' has been created successfully.\")\n",
    "\n",
    "print(\"\\nmicro_dev_question_ids: \" + json.dumps(sorted(list(micro_dev_question_ids)), indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mini_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
